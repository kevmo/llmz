{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "468e8b9e-da62-4197-9400-c084b7e0d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fastembed import TextEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f915460b-205c-4b70-9b56-5f140f47ab9b",
   "metadata": {},
   "source": [
    "## 1. Embedding the Query\n",
    "\n",
    "Embed the query: 'I just discovered the course. Can I join now?'. Use the 'jinaai/jina-embeddings-v2-small-en' model.\n",
    "\n",
    "You should get a numpy array of size 512.\n",
    "\n",
    "What's the minimal value in this array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56183454-b136-4757-b23e-c8f0b3f028d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EMBEDDINGS_REGISTRY',\n",
       " 'METADATA_FILE',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__firstlineno__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__static_attributes__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_get_model_description',\n",
       " '_list_supported_models',\n",
       " 'add_custom_model',\n",
       " 'decompress_to_cache',\n",
       " 'download_file_from_gcs',\n",
       " 'download_files_from_huggingface',\n",
       " 'download_model',\n",
       " 'embed',\n",
       " 'embedding_size',\n",
       " 'get_embedding_size',\n",
       " 'list_supported_models',\n",
       " 'passage_embed',\n",
       " 'query_embed',\n",
       " 'retrieve_model_gcs']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(TextEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23bfe3d7-06b3-471a-b77b-70ad72c2c43c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'BAAI/bge-base-en',\n",
       "  'sources': {'hf': 'Qdrant/fast-bge-base-en',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-base-en.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.42,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-base-en-v1.5',\n",
       "  'sources': {'hf': 'qdrant/bge-base-en-v1.5-onnx-q',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-base-en-v1.5.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.21,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-large-en-v1.5',\n",
       "  'sources': {'hf': 'qdrant/bge-large-en-v1.5-onnx',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 1.2,\n",
       "  'additional_files': [],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-small-en',\n",
       "  'sources': {'hf': 'Qdrant/bge-small-en',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/BAAI-bge-small-en.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.13,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-small-en-v1.5',\n",
       "  'sources': {'hf': 'qdrant/bge-small-en-v1.5-onnx-q',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.067,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-small-zh-v1.5',\n",
       "  'sources': {'hf': 'Qdrant/bge-small-zh-v1.5',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-small-zh-v1.5.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Chinese, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.09,\n",
       "  'additional_files': [],\n",
       "  'dim': 512,\n",
       "  'tasks': {}},\n",
       " {'model': 'mixedbread-ai/mxbai-embed-large-v1',\n",
       "  'sources': {'hf': 'mixedbread-ai/mxbai-embed-large-v1',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.64,\n",
       "  'additional_files': [],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-xs',\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-xs',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.09,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-s',\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-s',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.13,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-m',\n",
       "  'sources': {'hf': 'Snowflake/snowflake-arctic-embed-m',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.43,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-m-long',\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-m-long',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 2048 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.54,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-l',\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-l',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 1.02,\n",
       "  'additional_files': [],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-clip-v1',\n",
       "  'sources': {'hf': 'jinaai/jina-clip-v1',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/text_model.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text&image), English, Prefixes for queries/documents: not necessary, 2024 year',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.55,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'Qdrant/clip-ViT-B-32-text',\n",
       "  'sources': {'hf': 'Qdrant/clip-ViT-B-32-text',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text&image), English, 77 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.25,\n",
       "  'additional_files': [],\n",
       "  'dim': 512,\n",
       "  'tasks': {}},\n",
       " {'model': 'sentence-transformers/all-MiniLM-L6-v2',\n",
       "  'sources': {'hf': 'qdrant/all-MiniLM-L6-v2-onnx',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/sentence-transformers-all-MiniLM-L6-v2.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 256 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.09,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-en',\n",
       "  'sources': {'hf': 'xenova/jina-embeddings-v2-base-en',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.52,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-small-en',\n",
       "  'sources': {'hf': 'xenova/jina-embeddings-v2-small-en',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.12,\n",
       "  'additional_files': [],\n",
       "  'dim': 512,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-de',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-de',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model_fp16.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (German, English), 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.32,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-code',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-code',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (English, 30 programming languages), 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.64,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-zh',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-zh',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), supports mixed Chinese-English input text, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.64,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-es',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-es',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), supports mixed Spanish-English input text, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.64,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'thenlper/gte-base',\n",
       "  'sources': {'hf': 'thenlper/gte-base',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'General text embeddings, Unimodal (text), supports English only input text, 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.44,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'thenlper/gte-large',\n",
       "  'sources': {'hf': 'qdrant/gte-large-onnx',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 1.2,\n",
       "  'additional_files': [],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'nomic-ai/nomic-embed-text-v1.5',\n",
       "  'sources': {'hf': 'nomic-ai/nomic-embed-text-v1.5',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.52,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'nomic-ai/nomic-embed-text-v1.5-Q',\n",
       "  'sources': {'hf': 'nomic-ai/nomic-embed-text-v1.5',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model_quantized.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.13,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'nomic-ai/nomic-embed-text-v1',\n",
       "  'sources': {'hf': 'nomic-ai/nomic-embed-text-v1',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.52,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
       "  'sources': {'hf': 'qdrant/paraphrase-multilingual-MiniLM-L12-v2-onnx-Q',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~50 languages), 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2019 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.22,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
       "  'sources': {'hf': 'xenova/paraphrase-multilingual-mpnet-base-v2',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~50 languages), 384 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 1.0,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'intfloat/multilingual-e5-large',\n",
       "  'sources': {'hf': 'qdrant/multilingual-e5-large-onnx',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-multilingual-e5-large.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~100 languages), 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 2.24,\n",
       "  'additional_files': ['model.onnx_data'],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v3',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v3',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Multi-task unimodal (text) embedding model, multi-lingual (~100), 1024 tokens truncation, and 8192 sequence length. Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'cc-by-nc-4.0',\n",
       "  'size_in_GB': 2.29,\n",
       "  'additional_files': ['onnx/model.onnx_data'],\n",
       "  'dim': 1024,\n",
       "  'tasks': {'retrieval.query': 0,\n",
       "   'retrieval.passage': 1,\n",
       "   'separation': 2,\n",
       "   'classification': 3,\n",
       "   'text-matching': 4}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " TextEmbedding.list_supported_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0e09c08-d440-4092-855c-a16a17ed7f78",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EMBEDDINGS_REGISTRY',\n",
       " 'METADATA_FILE',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__firstlineno__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__static_attributes__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_embedding_size',\n",
       " '_get_model_description',\n",
       " '_list_supported_models',\n",
       " '_local_files_only',\n",
       " 'add_custom_model',\n",
       " 'cache_dir',\n",
       " 'decompress_to_cache',\n",
       " 'download_file_from_gcs',\n",
       " 'download_files_from_huggingface',\n",
       " 'download_model',\n",
       " 'embed',\n",
       " 'embedding_size',\n",
       " 'get_embedding_size',\n",
       " 'list_supported_models',\n",
       " 'model',\n",
       " 'model_name',\n",
       " 'passage_embed',\n",
       " 'query_embed',\n",
       " 'retrieve_model_gcs',\n",
       " 'threads']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = 'jinaai/jina-embeddings-v2-small-en'\n",
    "\n",
    "embedding_generator = TextEmbedding(MODEL)\n",
    "\n",
    "dir(embedding_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17d5b914-6ebd-4c26-b473-723f7a5de9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1 = 'I just discovered the course. Can I join now?'\n",
    "\n",
    "EMBEDDINGS_1 = list(embedding_generator.embed([QUERY_1]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ea75218-16ab-4e73-9575-01f17fe3efcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(-0.11726373551188797), np.float64(-0.11390704900216968), np.float64(-0.10993315241766108), np.float64(-0.10002002566126772), np.float64(-0.0990923940127248), np.float64(-0.09791743140235433), np.float64(-0.09760669466036077), np.float64(-0.09484544406877056), np.float64(-0.0900752289323632), np.float64(-0.08873296941672207), np.float64(-0.08835649651724337), np.float64(-0.08776025423533446), np.float64(-0.08585818588643464), np.float64(-0.08533977218377005), np.float64(-0.08251141106770632), np.float64(-0.0803499849369055), np.float64(-0.07802898795843768), np.float64(-0.07704189620264709), np.float64(-0.07648079261156313), np.float64(-0.07639463728739372), np.float64(-0.07638033962177995), np.float64(-0.07548960693705196), np.float64(-0.07305555140645403), np.float64(-0.07302608177518038), np.float64(-0.07302301320380362), np.float64(-0.07283665725790175), np.float64(-0.07282576410966378), np.float64(-0.07180559953250298), np.float64(-0.0714069569985842), np.float64(-0.07073716752289039), np.float64(-0.07033746625714006), np.float64(-0.06799304947687651), np.float64(-0.06756095755390411), np.float64(-0.06741564351670855), np.float64(-0.06718365447793304), np.float64(-0.06553277731816712), np.float64(-0.06450899857838584), np.float64(-0.06415199642264417), np.float64(-0.06261067722968362), np.float64(-0.062309831751108866), np.float64(-0.062199985463727556), np.float64(-0.06185557906509869), np.float64(-0.060277574872540075), np.float64(-0.05982757894217494), np.float64(-0.05972429971037358), np.float64(-0.05961664641030418), np.float64(-0.05922518994573629), np.float64(-0.05885133667798452), np.float64(-0.05885104625628696), np.float64(-0.05811966613603688), np.float64(-0.05676772581932451), np.float64(-0.056675579030166276), np.float64(-0.05665554343490413), np.float64(-0.054683897611307236), np.float64(-0.05418870317005398), np.float64(-0.05389486318110099), np.float64(-0.05388609893596593), np.float64(-0.05381924860038464), np.float64(-0.05203394156352984), np.float64(-0.051877895113899175), np.float64(-0.051748262447624004), np.float64(-0.05056501838317198), np.float64(-0.049186364289630344), np.float64(-0.04908401807255108), np.float64(-0.048756334384056396), np.float64(-0.04872396555515323), np.float64(-0.04861554137691234), np.float64(-0.04840415430240079), np.float64(-0.04833364719812199), np.float64(-0.04827297287604395), np.float64(-0.047790572864624264), np.float64(-0.047712752748230856), np.float64(-0.047581283993494386), np.float64(-0.04745770944445457), np.float64(-0.047174036899682595), np.float64(-0.04683423922375004), np.float64(-0.046379225902536216), np.float64(-0.04600294233746002), np.float64(-0.0454303586264716), np.float64(-0.04539497028154472), np.float64(-0.04516362795049021), np.float64(-0.044755049621047475), np.float64(-0.0439756771401825), np.float64(-0.043718090953982394), np.float64(-0.04355530819175352), np.float64(-0.04336501424786362), np.float64(-0.04328920989501109), np.float64(-0.04311432198756443), np.float64(-0.04272901013640468), np.float64(-0.04212570610150656), np.float64(-0.041627051112968015), np.float64(-0.041578352250213065), np.float64(-0.041458197510045175), np.float64(-0.04120442217479369), np.float64(-0.04113031841724112), np.float64(-0.04080076923917377), np.float64(-0.04026710774078689), np.float64(-0.04006707063336918), np.float64(-0.04002299785674603), np.float64(-0.03998673325656266), np.float64(-0.03995974289041975), np.float64(-0.039942735452773485), np.float64(-0.03878842893608281), np.float64(-0.0386447496882258), np.float64(-0.03854166364288323), np.float64(-0.038310171315091845), np.float64(-0.03776227823428393), np.float64(-0.037621814694680615), np.float64(-0.03750645754469562), np.float64(-0.03722528352533577), np.float64(-0.03685241486651442), np.float64(-0.03668026314467935), np.float64(-0.036442842706551994), np.float64(-0.03633578227296245), np.float64(-0.03620138134466014), np.float64(-0.0360949523418866), np.float64(-0.03534081818356748), np.float64(-0.034922988396826136), np.float64(-0.03459507183402011), np.float64(-0.03444016512613179), np.float64(-0.034277281597612556), np.float64(-0.033893054217024), np.float64(-0.0337173864140923), np.float64(-0.03290736854932159), np.float64(-0.032794659994441214), np.float64(-0.03276378974675025), np.float64(-0.03246169299189456), np.float64(-0.032258900672041846), np.float64(-0.03167893694650537), np.float64(-0.03149267736037494), np.float64(-0.03143176496225046), np.float64(-0.030929100719978304), np.float64(-0.030861660173501403), np.float64(-0.03081416875529611), np.float64(-0.03072732131583321), np.float64(-0.030351442479306396), np.float64(-0.03030058634830685), np.float64(-0.030297444587860795), np.float64(-0.030199489773302828), np.float64(-0.029661295411464304), np.float64(-0.029555889786233056), np.float64(-0.0293922192417611), np.float64(-0.028836033488122494), np.float64(-0.02761256457221371), np.float64(-0.02749731746847284), np.float64(-0.02745794498842932), np.float64(-0.027430398437887922), np.float64(-0.02700642396478283), np.float64(-0.02694512590141022), np.float64(-0.02693901133112283), np.float64(-0.026777710472453406), np.float64(-0.026480803998654122), np.float64(-0.026417384211010746), np.float64(-0.026360856766131518), np.float64(-0.02587557556982275), np.float64(-0.025846535151001642), np.float64(-0.02556655191312982), np.float64(-0.025548323399177925), np.float64(-0.02519947803644086), np.float64(-0.024481368974152578), np.float64(-0.024378432983911374), np.float64(-0.024058391804254283), np.float64(-0.023921720117958397), np.float64(-0.023901829967002988), np.float64(-0.023460509494793936), np.float64(-0.023082502747360522), np.float64(-0.022789439551455206), np.float64(-0.02271534737537795), np.float64(-0.02270576604039128), np.float64(-0.021845530187353263), np.float64(-0.021506862798115825), np.float64(-0.02138859597407553), np.float64(-0.021334423514443153), np.float64(-0.02129510969071114), np.float64(-0.02086682845088945), np.float64(-0.020779189800526187), np.float64(-0.020138579928368764), np.float64(-0.02009639773804858), np.float64(-0.019654916424251025), np.float64(-0.019640071168409778), np.float64(-0.019638904013596477), np.float64(-0.0195920285012531), np.float64(-0.01946820607822825), np.float64(-0.019346198032074775), np.float64(-0.019198697340114385), np.float64(-0.01903596059828513), np.float64(-0.018864503807830158), np.float64(-0.018814257483603415), np.float64(-0.018693500217632726), np.float64(-0.018610549629193077), np.float64(-0.018599793404046428), np.float64(-0.018330182134116413), np.float64(-0.01827982459635577), np.float64(-0.018193571978583116), np.float64(-0.017958986427713895), np.float64(-0.017559810435069538), np.float64(-0.017316686670140257), np.float64(-0.01701786339708686), np.float64(-0.0170145764695654), np.float64(-0.016942264199061155), np.float64(-0.01676486674625728), np.float64(-0.016706945841906212), np.float64(-0.01634716692993751), np.float64(-0.015575371830435898), np.float64(-0.015485658446511123), np.float64(-0.015259781825832458), np.float64(-0.014254159075285835), np.float64(-0.014245715442248215), np.float64(-0.014179694425930868), np.float64(-0.014179054380881052), np.float64(-0.013769255051736075), np.float64(-0.013692144517121474), np.float64(-0.013540243130830746), np.float64(-0.012732243491852792), np.float64(-0.012544880138391959), np.float64(-0.012489694887076503), np.float64(-0.012423638396093149), np.float64(-0.011791864747076922), np.float64(-0.01114599024115181), np.float64(-0.011040768073748578), np.float64(-0.011002601520777998), np.float64(-0.010720440492248112), np.float64(-0.010597075654113044), np.float64(-0.009961036706349699), np.float64(-0.009829063624063265), np.float64(-0.009775123469688469), np.float64(-0.00962880078468856), np.float64(-0.009244942260375304), np.float64(-0.008855490178272923), np.float64(-0.008810411599114254), np.float64(-0.008660061432421241), np.float64(-0.008470530658942495), np.float64(-0.008279114657750433), np.float64(-0.008216670388768308), np.float64(-0.008004709518373695), np.float64(-0.007829256933127474), np.float64(-0.007765002286609392), np.float64(-0.00767204395382191), np.float64(-0.007580136350091369), np.float64(-0.00723996466676139), np.float64(-0.0069495763391002234), np.float64(-0.0067402432422787595), np.float64(-0.005960282768368763), np.float64(-0.005925364053303097), np.float64(-0.005178384447510783), np.float64(-0.004817930692489556), np.float64(-0.004599760041086992), np.float64(-0.004552796748552067), np.float64(-0.004341011197787026), np.float64(-0.0038696174376895522), np.float64(-0.0035177742322170112), np.float64(-0.0034366209964568364), np.float64(-0.00329058230576513), np.float64(-0.002214646924609066), np.float64(-0.001996389944831622), np.float64(-0.0012190530568426852), np.float64(-0.001195888318807472), np.float64(-0.0007629667665097797), np.float64(0.00010342164115466367), np.float64(0.00014572482288455942), np.float64(0.00021839073659524473), np.float64(0.0006322117620533498), np.float64(0.000803683931551192), np.float64(0.0008719738053684404), np.float64(0.0010480241656392463), np.float64(0.0014446840615124877), np.float64(0.001534195989459936), np.float64(0.002455552693954825), np.float64(0.0026018404505438655), np.float64(0.0027003817438619533), np.float64(0.002704374513731164), np.float64(0.0027545754632154413), np.float64(0.0033785235650608276), np.float64(0.0035516870681437697), np.float64(0.003878810414055103), np.float64(0.0038809885427598324), np.float64(0.004302227797827143), np.float64(0.0051033167347613526), np.float64(0.005637152969132911), np.float64(0.005724942681384986), np.float64(0.006220036480372419), np.float64(0.006872845309544332), np.float64(0.006969769912443128), np.float64(0.007057635126457362), np.float64(0.007120266898656149), np.float64(0.0071695875839730945), np.float64(0.0072020520066137786), np.float64(0.007308474742500298), np.float64(0.007701600540888694), np.float64(0.008071287805843156), np.float64(0.008201551067877564), np.float64(0.008481095671079643), np.float64(0.008522942571431342), np.float64(0.008567896881307482), np.float64(0.008702629919055608), np.float64(0.009131957524732705), np.float64(0.009857895973480876), np.float64(0.01004137227385706), np.float64(0.010325964759705585), np.float64(0.010713262666881286), np.float64(0.0108133167791551), np.float64(0.011338954123310426), np.float64(0.011537589947678919), np.float64(0.011661385781119277), np.float64(0.011728564212675813), np.float64(0.012231815319688871), np.float64(0.01223916388786059), np.float64(0.012251370266284641), np.float64(0.012258739847268326), np.float64(0.012377694140241634), np.float64(0.012427921284438157), np.float64(0.012625089324893823), np.float64(0.012716982855942912), np.float64(0.012896852814540135), np.float64(0.012957036648747686), np.float64(0.012985256674423896), np.float64(0.01315354700166283), np.float64(0.013445538153161437), np.float64(0.01383048828675247), np.float64(0.0138715618581941), np.float64(0.013951245195240665), np.float64(0.014258415772110409), np.float64(0.014323799539401745), np.float64(0.014397328567239426), np.float64(0.014898387122166401), np.float64(0.015117645421357045), np.float64(0.01535784561418706), np.float64(0.015716732330098203), np.float64(0.01586222353270029), np.float64(0.015979148236132428), np.float64(0.016015016402819424), np.float64(0.016113634624637847), np.float64(0.016236470067674903), np.float64(0.01626640705989025), np.float64(0.01637497462508964), np.float64(0.01659859775636793), np.float64(0.016712871223702318), np.float64(0.016882070953579745), np.float64(0.017316851261647184), np.float64(0.017482153203021752), np.float64(0.01765662157557771), np.float64(0.01791278163278322), np.float64(0.01814456385699176), np.float64(0.018433810648202546), np.float64(0.01849354648388764), np.float64(0.019291759693012493), np.float64(0.020093569788869076), np.float64(0.020459492677708205), np.float64(0.020605934449976368), np.float64(0.02079718177049949), np.float64(0.021025541537547418), np.float64(0.021302021182043402), np.float64(0.021369671025857934), np.float64(0.021767156367052155), np.float64(0.021816241661089166), np.float64(0.02181977014463972), np.float64(0.022047040618750534), np.float64(0.022906098924448413), np.float64(0.02316816942943639), np.float64(0.02319588436244067), np.float64(0.023290597116266198), np.float64(0.02331552528991718), np.float64(0.02374375300220684), np.float64(0.024005959219223), np.float64(0.02438887222969405), np.float64(0.024459179670879665), np.float64(0.024465054115067948), np.float64(0.024650110225433983), np.float64(0.02466856604718408), np.float64(0.024871990184517547), np.float64(0.025452509437852006), np.float64(0.025475218637402333), np.float64(0.02578339011419051), np.float64(0.025932809655457693), np.float64(0.026071295952082917), np.float64(0.026264104384072708), np.float64(0.026369430429323125), np.float64(0.026986283897085274), np.float64(0.027150470792191933), np.float64(0.027291788466910386), np.float64(0.027850356237673728), np.float64(0.028018660904338067), np.float64(0.028173200940971654), np.float64(0.028238225299739364), np.float64(0.029698823311013353), np.float64(0.029709126569360415), np.float64(0.029866881172492366), np.float64(0.030086046249002858), np.float64(0.03033098689318098), np.float64(0.0311805552205046), np.float64(0.03132663389087131), np.float64(0.031453982495697176), np.float64(0.0315629248594064), np.float64(0.03198324752479556), np.float64(0.03201234225177373), np.float64(0.03206533881286279), np.float64(0.032158228932153685), np.float64(0.03249059911402634), np.float64(0.032787939980126565), np.float64(0.03338373974247943), np.float64(0.033654638284989005), np.float64(0.03378948505415157), np.float64(0.033866950436652145), np.float64(0.033903267156324246), np.float64(0.03424840480363652), np.float64(0.03490392982311084), np.float64(0.03499540728830855), np.float64(0.03584334176012544), np.float64(0.036326828168144476), np.float64(0.036499084654237415), np.float64(0.036944650515607254), np.float64(0.03721094558822455), np.float64(0.03814698487487439), np.float64(0.0386115387764745), np.float64(0.038911234124427846), np.float64(0.03919630426525483), np.float64(0.03926707114987443), np.float64(0.039594743457293746), np.float64(0.03984268479494787), np.float64(0.040090636521481045), np.float64(0.040699397169190264), np.float64(0.04078055824403088), np.float64(0.04149426501334899), np.float64(0.04173062140847632), np.float64(0.041953191177456065), np.float64(0.042180151181667326), np.float64(0.042423889575735334), np.float64(0.04255419390055059), np.float64(0.042957238400963195), np.float64(0.043155371950570245), np.float64(0.043354778896599576), np.float64(0.045931139891711055), np.float64(0.04603156638401618), np.float64(0.04651549951383448), np.float64(0.046878088902113764), np.float64(0.04731130959430457), np.float64(0.04764798383624064), np.float64(0.047769799425491435), np.float64(0.04982126691726951), np.float64(0.049868029771557895), np.float64(0.05002581069707441), np.float64(0.05044275878607066), np.float64(0.05164704640051089), np.float64(0.05169634840189577), np.float64(0.05172879777379384), np.float64(0.05236319035416313), np.float64(0.05279285338055884), np.float64(0.05304640447944337), np.float64(0.05313392331480615), np.float64(0.05355874127150713), np.float64(0.053660782825953504), np.float64(0.05469554751351036), np.float64(0.05575563818707563), np.float64(0.05586287359740336), np.float64(0.056092093357902016), np.float64(0.05612665820907052), np.float64(0.05622061079552024), np.float64(0.05700348847250464), np.float64(0.057454240689918994), np.float64(0.058543832628310984), np.float64(0.05865016315560035), np.float64(0.05881551628992738), np.float64(0.05928467269840571), np.float64(0.06002884281278818), np.float64(0.060257968489730473), np.float64(0.06056569035567718), np.float64(0.06123750461222543), np.float64(0.06201592627719914), np.float64(0.06217636488808945), np.float64(0.06224143965918459), np.float64(0.0631239207724494), np.float64(0.06332493647725516), np.float64(0.06379748806479102), np.float64(0.0638997743999045), np.float64(0.06392792919596864), np.float64(0.06598339039463956), np.float64(0.0673376092610048), np.float64(0.06807165640494692), np.float64(0.06881412134241705), np.float64(0.0693626768018113), np.float64(0.06940393045688391), np.float64(0.07013559096013944), np.float64(0.07103455023632926), np.float64(0.07153643628298212), np.float64(0.07207026731561858), np.float64(0.07316814187538191), np.float64(0.07334755174671188), np.float64(0.07377335688038081), np.float64(0.07425891020841537), np.float64(0.07527368073949732), np.float64(0.07590285483417086), np.float64(0.07610612737703955), np.float64(0.07622170984313456), np.float64(0.0772684692502959), np.float64(0.079713806403171), np.float64(0.07987353460150047), np.float64(0.080588348778634), np.float64(0.0837960027328298), np.float64(0.08491594117057906), np.float64(0.0867279129580923), np.float64(0.08948578074389667), np.float64(0.09002534083477919), np.float64(0.09236919054566702), np.float64(0.09316497214426646), np.float64(0.09482542738360288), np.float64(0.09963437552952939), np.float64(0.0999905735393408), np.float64(0.10176959273633132), np.float64(0.1055643948512088), np.float64(0.11117786806311172), np.float64(0.12317111034564432), np.float64(0.13307955253468784)]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8de347b0-86c3-49d6-9c7f-968c45029bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of EMBEDDINGS_1: <class 'numpy.ndarray'>\n",
      "\n",
      "First 5 smallest values: [np.float64(-0.11726373551188797), np.float64(-0.11390704900216968), np.float64(-0.10993315241766108), np.float64(-0.10002002566126772), np.float64(-0.0990923940127248)]\n",
      "Last 5 largest values: [np.float64(0.10176959273633132), np.float64(0.1055643948512088), np.float64(0.11117786806311172), np.float64(0.12317111034564432), np.float64(0.13307955253468784)]\n",
      "\n",
      "Minimum value using sorted()[0]: -0.11726373551188797\n",
      "Minimum value using np.min(): -0.11726373551188797\n"
     ]
    }
   ],
   "source": [
    "# Check the type of EMBEDDINGS_1\n",
    "print(f\"Type of EMBEDDINGS_1: {type(EMBEDDINGS_1)}\")\n",
    "\n",
    "# If it's a numpy array, sorted() converts it to a list first\n",
    "# Let's see the first few and last few values when sorted\n",
    "sorted_embeddings = sorted(EMBEDDINGS_1)\n",
    "print(f\"\\nFirst 5 smallest values: {sorted_embeddings[:5]}\")\n",
    "print(f\"Last 5 largest values: {sorted_embeddings[-5:]}\")\n",
    "\n",
    "# The minimum value (first element after sorting)\n",
    "print(f\"\\nMinimum value using sorted()[0]: {sorted_embeddings[0]}\")\n",
    "\n",
    "# More efficient way using numpy\n",
    "if isinstance(EMBEDDINGS_1, np.ndarray):\n",
    "    print(f\"Minimum value using np.min(): {np.min(EMBEDDINGS_1)}\")\n",
    "else:\n",
    "    # Convert to numpy array first\n",
    "    arr = np.array(EMBEDDINGS_1)\n",
    "    print(f\"Minimum value using np.min(): {np.min(arr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d69ad8-4557-402c-9708-a014da265c2e",
   "metadata": {},
   "source": [
    "# Cosine similarity\n",
    "\n",
    "The vectors that our embedding model returns are already normalized: their length is 1.0.\n",
    "\n",
    "You can check that by using the norm function:\n",
    "\n",
    "import numpy as np\n",
    "np.linalg.norm(q)\n",
    "\n",
    "Which means that we can simply compute the dot product between two vectors to learn the cosine similarity between them.\n",
    "\n",
    "For example, if you compute the cosine of the query vector with itself, the result will be 1.0:\n",
    "\n",
    "q.dot(q)\n",
    "\n",
    "## Q2. Cosine similarity with another vector\n",
    "\n",
    "Now let's embed this document:\n",
    "\n",
    "doc = 'Can I still join the course after the start date?'\n",
    "\n",
    "What's the cosine similarity between the vector for the query and the vector for the document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54540408-aad9-4a94-890e-93bf5931e3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9008528856818037\n"
     ]
    }
   ],
   "source": [
    "QUERY_2 = 'Can I still join the course after the start date?'\n",
    "Q2_DOCS = [QUERY_2]\n",
    "EMBEDDINGS_2 = list(embedding_generator.embed(Q2_DOCS))[0]\n",
    "\n",
    "print(EMBEDDINGS_1.dot(EMBEDDINGS_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcb0f60-c2ee-4918-be24-27d9d6ca9f54",
   "metadata": {},
   "source": [
    "## Q3. Ranking by cosine\n",
    "\n",
    "For Q3 and Q4 we will use these documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dabd20c-c642-46c1-8365-35b240f36330",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I still join the course after the start date?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I follow the course after it finishes?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - When will the course start?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - What can I do before the course starts?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'How can we contribute to the course?',\n",
    "  'course': 'data-engineering-zoomcamp'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f56b5-f96d-4dd4-8ccc-620cce365edb",
   "metadata": {},
   "source": [
    "Compute the embeddings for the text field, and compute the cosine between the query vector and all the documents.\n",
    "\n",
    "What's the document index with the highest similarity? (Indexing starts from 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef70114-40aa-4d4e-950d-770c0de0eff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e245eb7e-3bf7-4418-92e0-a194d9104b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.7629684493123693), np.float64(0.8182378361919107), np.float64(0.8085397290762828), np.float64(0.7133078539597724), np.float64(0.7304499528359614)]\n"
     ]
    }
   ],
   "source": [
    "Q3_EMBEDDINGS = list(embedding_generator.embed([d['text'] for d in documents]))\n",
    "\n",
    "similarities = [EMBEDDINGS_1.dot(e) for e in Q3_EMBEDDINGS]\n",
    "\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db02fe-3de7-4b58-a755-c01a72bef926",
   "metadata": {},
   "source": [
    "Looks like Document 1 is the winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498886fd-09d7-46ff-9e05-0e18dd1afa60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "qusr3zsikp",
   "metadata": {},
   "source": [
    "### Alternative elegant solution using numpy and batch embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2u1t03l7vja",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'I just discovered the course. Can I join now?'\n",
      "\n",
      "Cosine similarities:\n",
      "[0] 0.7630 - Course - Can I still join the course after the start date?\n",
      "[1] 0.8182 - Course - Can I follow the course after it finishes?\n",
      "[2] 0.8085 - Course - When will the course start?\n",
      "[3] 0.7133 - Course - What can I do before the course starts?\n",
      "[4] 0.7304 - How can we contribute to the course?\n",
      "\n",
      "Best match: Document 1\n",
      "Question: Course - Can I follow the course after it finishes?\n",
      "Similarity: 0.8182\n",
      "\n",
      "✓ Results match your implementation!\n"
     ]
    }
   ],
   "source": [
    "# More elegant solution leveraging numpy and fastembed features\n",
    "\n",
    "# Extract all document texts efficiently\n",
    "doc_texts = [doc['text'] for doc in documents]\n",
    "\n",
    "# Embed all documents in one batch - fastembed returns a generator\n",
    "doc_embeddings = np.array(list(embedding_generator.embed(doc_texts)))\n",
    "\n",
    "# Compute all cosine similarities at once using matrix multiplication\n",
    "# Since embeddings are normalized, dot product = cosine similarity\n",
    "cosine_similarities = doc_embeddings @ EMBEDDINGS_1\n",
    "\n",
    "# Find the index with highest similarity\n",
    "best_match_idx = np.argmax(cosine_similarities)\n",
    "\n",
    "# Display results in a clean format\n",
    "print(f\"Query: '{QUERY_1}'\")\n",
    "print(f\"\\nCosine similarities:\")\n",
    "for idx, (sim, doc) in enumerate(zip(cosine_similarities, documents)):\n",
    "    print(f\"[{idx}] {sim:.4f} - {doc['question']}\")\n",
    "    \n",
    "print(f\"\\nBest match: Document {best_match_idx}\")\n",
    "print(f\"Question: {documents[best_match_idx]['question']}\")\n",
    "print(f\"Similarity: {cosine_similarities[best_match_idx]:.4f}\")\n",
    "\n",
    "# Verify it matches your result\n",
    "assert best_match_idx == np.argmax(similarities), \"Results should match!\"\n",
    "print(\"\\n✓ Results match your implementation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a76aabd-ed38-4469-b80c-a216964e8f60",
   "metadata": {},
   "source": [
    "## Q4. Ranking by cosine, version two\n",
    "\n",
    "Now let's calculate a new field, which is a concatenation of question and text:\n",
    "\n",
    "full_text = doc['question'] + ' ' + doc['text']\n",
    "\n",
    "Embed this field and compute the cosine between it and the query vector. What's the highest scoring document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80e68878-0c10-4fa8-ab61-577f5a252d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'I just discovered the course. Can I join now?'\n",
      "\n",
      "Cosine similarities:\n",
      "[0] 0.8515 - Course - Can I still join the course after the start date?\n",
      "[1] 0.8437 - Course - Can I follow the course after it finishes?\n",
      "[2] 0.8408 - Course - When will the course start?\n",
      "[3] 0.7755 - Course - What can I do before the course starts?\n",
      "[4] 0.8086 - How can we contribute to the course?\n",
      "\n",
      "Best match: Document 0\n",
      "Question: Course - Can I still join the course after the start date?\n",
      "Similarity: 0.8515\n",
      "\n",
      "✓ Results match your implementation!\n"
     ]
    }
   ],
   "source": [
    "# Extract all document texts efficiently\n",
    "doc_texts2 = [doc['question'] + ' ' + doc['text'] for doc in documents]\n",
    "\n",
    "# Embed all documents in one batch - fastembed returns a generator\n",
    "doc_embeddings2 = np.array(list(embedding_generator.embed(doc_texts2)))\n",
    "\n",
    "# Compute all cosine similarities at once using matrix multiplication\n",
    "# Since embeddings are normalized, dot product = cosine similarity\n",
    "cosine_similarities = doc_embeddings2 @ EMBEDDINGS_1\n",
    "\n",
    "# Find the index with highest similarity\n",
    "best_match_idx = np.argmax(cosine_similarities)\n",
    "\n",
    "# Display results in a clean format\n",
    "print(f\"Query: '{QUERY_1}'\")\n",
    "print(f\"\\nCosine similarities:\")\n",
    "for idx, (sim, doc) in enumerate(zip(cosine_similarities, documents)):\n",
    "    print(f\"[{idx}] {sim:.4f} - {doc['question']}\")\n",
    "    \n",
    "print(f\"\\nBest match: Document {best_match_idx}\")\n",
    "print(f\"Question: {documents[best_match_idx]['question']}\")\n",
    "print(f\"Similarity: {cosine_similarities[best_match_idx]:.4f}\")\n",
    "\n",
    "# Verify it matches your result\n",
    "# assert best_match_idx == np.argmax(similarities), \"Results should match!\"\n",
    "print(\"\\n✓ Results match your implementation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00192280-2ab7-4740-8d52-794a06013c2a",
   "metadata": {},
   "source": [
    "## Q5. Selecting the embedding model\n",
    "\n",
    "Now let's select a smaller embedding model. What's the smallest dimensionality for models in fastembed?\n",
    "\n",
    "One of these models is BAAI/bge-small-en. Let's use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0d122ed-b13b-4577-8311-02f3d605ed8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[384, 384, 384, 384, 384, 384, 512, 512, 512, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 1024, 1024, 1024, 1024, 1024, 1024]\n"
     ]
    }
   ],
   "source": [
    "print(sorted([m['dim'] for m in  TextEmbedding.list_supported_models()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36a4e027-6f9b-4d7d-9dab-6d350ffd90e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model': 'BAAI/bge-small-en', 'sources': {'hf': 'Qdrant/bge-small-en', 'url': 'https://storage.googleapis.com/qdrant-fastembed/BAAI-bge-small-en.tar.gz', '_deprecated_tar_struct': True}, 'model_file': 'model_optimized.onnx', 'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.', 'license': 'mit', 'size_in_GB': 0.13, 'additional_files': [], 'dim': 384, 'tasks': {}}]\n"
     ]
    }
   ],
   "source": [
    "print([m for m in TextEmbedding.list_supported_models() if m['model'] == \"BAAI/bge-small-en\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fad57a7-55db-48c6-b934-cf41183ab065",
   "metadata": {},
   "source": [
    "## Q6. Indexing with qdrant (2 points)\n",
    "\n",
    "For the last question, we will use more documents.\n",
    "\n",
    "We will select only FAQ records from our ml zoomcamp:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "849f0fc8-48a0-4a50-a2cd-83fdf21ad85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    if course_name != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        doc['qa_text'] = doc['question'] + ' ' + doc['text']\n",
    "        documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffa50c18-5544-4da4-a1f0-ae787b637f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Is it going to be live? When?',\n",
       " 'course': 'machine-learning-zoomcamp'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d179ca53-609c-480a-8e9c-b5ddbed8796d",
   "metadata": {},
   "source": [
    "-----\n",
    "Add them to qdrant using the model form Q5.\n",
    "\n",
    "When adding the data, use both question and answer fields:\n",
    "\n",
    "text = doc['question'] + ' ' + doc['text']\n",
    "\n",
    "After the data is inserted, use the question from Q1 for querying the collection.\n",
    "\n",
    "What's the highest score in the results? (The score for the first returned record):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a1377ef-f8d0-4eba-b691-def6953192e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c298512c-2d1b-4fb9-a347-e501363399f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(\"http://localhost:6333\") #connecting to local Qdrant instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "207ad2a6-41d6-41b0-a1e0-aba66b952b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name = \"mlz-rag\"\n",
    "\n",
    "# Create the collection with specified vector parameters\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=384,  # Dimensionality of the vectors\n",
    "        distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8024861-5fb7-4e1f-8d17-94dd64aa8b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "id = 0\n",
    "\n",
    "for course in documents:\n",
    "    point = models.PointStruct(\n",
    "        id=id,\n",
    "        vector=models.Document(text=doc['qa_text'], model=model_handle),\n",
    "        payload={\n",
    "            \"text\": doc['qa_text'],\n",
    "        } #save all needed metadata fields\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "    id += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
